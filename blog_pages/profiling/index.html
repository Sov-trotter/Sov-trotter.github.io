<!doctype html> <!-- Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes Free for personal and commercial use under the MIT license https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE --> <html lang=en > <script async src="https://www.googletagmanager.com/gtag/js?id=G-VMEHDXB8JF"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-VMEHDXB8JF'); </script> <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/minimal-mistakes.css"> <link rel=stylesheet  href="/css/adjust.css"> <!--[if IE ]> <style> /* old IE unsupported flexbox fixes */ .greedy-nav .site-title { padding-right: 3em; } .greedy-nav button { position: absolute; top: 0; right: 0; height: 100%; } </style> <![endif]--> <title>But what is Performance Analysis and profiling?</title> <body class=layout--single > <div class=masthead > <div class=masthead__inner-wrap > <div class=masthead__menu > <nav id=site-nav  class=greedy-nav > <a class=site-title  href="/">Arsh Sharma</a> <div class=nav-social-icons > <a href="https://x.com/Sov_trotter" target=_blank  class=nav-social-icon  title="X (formerly Twitter)"> <svg width=18  height=18  viewBox="0 0 24 24" fill=currentColor > <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/> </svg> </a> <a href="https://linkedin.com/in/Sov-trotter" target=_blank  class=nav-social-icon  title=LinkedIn > <svg width=18  height=18  viewBox="0 0 24 24" fill=currentColor > <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/> </svg> </a> <a href="https://github.com/Sov-trotter" target=_blank  class=nav-social-icon  title=GitHub > <svg width=18  height=18  viewBox="0 0 24 24" fill=currentColor > <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/> </svg> </a> <a href="mailto:sharmarsh15@gmail.com" class=nav-social-icon  title=Email > <svg width=18  height=18  viewBox="0 0 24 24" fill=currentColor > <path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/> </svg> </a> </div> <ul class=visible-links > <li class=masthead__menu-item ><a href="/assets/Arsh Sharma Resume.pdf" >Resume</a> <li class=masthead__menu-item ><a href="/about/" >About Me</a> <li class=masthead__menu-item ><a href="/blog/" >Blog</a> </ul> <button class="greedy-nav__toggle hidden" type=button > <span class=visually-hidden >Toggle menu</span> <div class=navicon ></div> </button> <ul class="hidden-links hidden"></ul> </nav> </div> </div> </div> <div class="blog-container "> <div class=blog-breadcrumbs > <a href="/">Home</a> » <a href="/blog/">Posts</a> </div> <div class=blog-post > <h1 class=blog-title >But what is Performance Analysis and profiling?</h1> <div class=blog-meta > <span class=blog-date >2025-08-31</span> <span class=blog-sep > · </span> <span class=blog-author >Arsh Sharma</span> </div> <div class=blog-content > </div> </div> </div> <div class=franklin-content ><div class=franklin-toc ><ol><li><a href="#introduction">Introduction</a><li><a href="#matrix_multiplication_profiling_results">Matrix Multiplication Profiling Results</a><ol><li><a href="#experimental_setup">Experimental Setup</a><li><a href="#performance_comparison_table">Performance Comparison Table</a><li><a href="#key_observations">Key Observations</a><li><a href="#detailed_metrics">Detailed Metrics</a><ol><li><a href="#instructions_and_cycles">Instructions and Cycles</a></ol><li><a href="#cache_behavior">Cache Behavior</a><li><a href="#analysis">Analysis</a><li><a href="#what_we_learned">What We Learned</a></ol></ol></div> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p>Performance profiling helps us understand how our code executes on real hardware and identify bottlenecks. Using tools like <code>perf</code> on Linux, we can collect hardware performance counters to gain deep insights into cache behavior, instruction execution, and branch prediction.</p> <h2 id=matrix_multiplication_profiling_results ><a href="#matrix_multiplication_profiling_results" class=header-anchor >Matrix Multiplication Profiling Results</a></h2> <p>In the <a href="../mat_mul/">Matrix Multiplication blog</a>, we implemented several cache-aware optimizations. Here we profile each approach using <code>perf</code> on Linux with a 4096×4096 matrix size to understand their performance characteristics.</p> <h3 id=experimental_setup ><a href="#experimental_setup" class=header-anchor >Experimental Setup</a></h3> <p><strong>System Specifications:</strong></p> <pre><code class="julia hljs">OS: Garuda Linux x86_64
Host: Victus by HP Laptop <span class=hljs-number >16</span>-e0xxx
Kernel: <span class=hljs-number >6.7</span><span class=hljs-number >.9</span>-zen1-<span class=hljs-number >1</span>-zen

CPU: AMD Ryzen <span class=hljs-number >5</span> <span class=hljs-number >5600</span>H (<span class=hljs-number >6</span> cores, <span class=hljs-number >12</span> threads) @ <span class=hljs-number >4.28</span> GHz
  - L1 Cache: <span class=hljs-number >384</span> KB
  - L2 Cache: <span class=hljs-number >3</span> MB
GPU: AMD Radeon RX <span class=hljs-number >5500</span>M
GPU: AMD Radeon Vega Series / Radeon Vega Mobile Series
Memory: <span class=hljs-number >16</span> GB DDR4</code></pre> <p><strong>Compilation Command:</strong></p> <pre><code class="bash hljs">g++ -mavx -mfma -march=native -O0 -o simd_matmul \
    ../../../matmul_perf_profiling-master/specific_runner.cpp</code></pre> <p><strong>Profiling Command:</strong></p> <pre><code class="bash hljs"><span class=hljs-built_in >sudo</span> perf <span class=hljs-built_in >stat</span> -e <span class=hljs-string >&quot;L1-dcache-loads,L1-dcache-load-misses,\
L1-dcache-prefetches,L1-icache-loads,L1-icache-load-misses,\
dTLB-loads,dTLB-load-misses,iTLB-loads,iTLB-load-misses,\
branch-loads,branch-load-misses,branch-instructions,branch-misses,\
cache-misses,cache-references,cpu-cycles,instructions&quot;</span> -C 3 \
numactl -C 3 ./&lt;bin_name&gt;</code></pre> <p>Note: We used <code>-O0</code> &#40;no compiler optimizations&#41; to isolate the impact of our manual cache-aware optimizations. The code was pinned to CPU core 3 using <code>numactl</code> to ensure consistent measurements.</p> <h3 id=performance_comparison_table ><a href="#performance_comparison_table" class=header-anchor >Performance Comparison Table</a></h3> <table><tr><th align=right >Approach<th align=right >Time &#40;s&#41;<th align=right >Speedup<th align=right >IPC<th align=right >L1 D-cache Loads<th align=right >L1 D-cache Misses<th align=right >L1 D-Miss Rate<th align=right >Cache Refs<th align=right >Cache Miss Rate<tr><td align=right >Simple MatMul<td align=right >268.27<td align=right >1.00×<td align=right >1.70<td align=right >486.39B<td align=right >71.92B<td align=right >14.79&#37;<td align=right >188.35B<td align=right >45.85&#37;<tr><td align=right >Loop Reordered<td align=right >148.63<td align=right ><span class=positive >↓</span> 1.80×<td align=right ><span class=positive >↑</span> 5.20<td align=right ><span class=positive >↑</span> 895.81B<td align=right ><span class=positive >↓</span> 5.69B<td align=right ><span class=positive >↓</span> 0.64&#37;<td align=right ><span class=positive >↓</span> 11.16B<td align=right ><span class=positive >↓</span> 2.04&#37;<tr><td align=right >Half Tiled<td align=right >146.10<td align=right ><span class=positive >↓</span> 1.84×<td align=right ><span class=positive >↑</span> 5.27<td align=right ><span class=positive >↑</span> 896.14B<td align=right ><span class=positive >↓</span> 5.60B<td align=right ><span class=positive >↓</span> 0.62&#37;<td align=right ><span class=positive >↓</span> 10.99B<td align=right ><span class=positive >↓</span> 1.98&#37;<tr><td align=right >Inner Tiled &#40;512&#41;<td align=right >148.35<td align=right ><span class=positive >↓</span> 1.81×<td align=right ><span class=positive >↑</span> 5.19<td align=right ><span class=positive >↑</span> 896.33B<td align=right ><span class=positive >↓</span> 5.78B<td align=right ><span class=positive >↓</span> 0.65&#37;<td align=right ><span class=positive >↓</span> 11.31B<td align=right ><span class=positive >↓</span> 2.64&#37;<tr><td align=right >Inner Tiled &#40;64&#41;<td align=right >148.68<td align=right ><span class=positive >↓</span> 1.80×<td align=right ><span class=positive >↑</span> 5.18<td align=right ><span class=positive >↑</span> 895.92B<td align=right ><span class=positive >↓</span> 5.79B<td align=right ><span class=positive >↓</span> 0.65&#37;<td align=right ><span class=positive >↓</span> 11.39B<td align=right ><span class=positive >↓</span> 2.32&#37;<tr><td align=right >Fully Tiled &#40;512&#41;<td align=right >281.01<td align=right ><span class=negative >↑</span> 0.95×<td align=right ><span class=positive >↑</span> 4.32<td align=right ><span class=negative >↑</span> 1,508.94B<td align=right ><span class=positive >↓</span> 6.13B<td align=right ><span class=positive >↓</span> 0.41&#37;<td align=right ><span class=negative >↑</span> 21.09B<td align=right ><span class=negative >↑</span> 26.13&#37;<tr><td align=right >Fully Tiled &#40;64&#41;<td align=right >270.62<td align=right ><span class=negative >↑</span> 0.99×<td align=right ><span class=positive >↑</span> 4.52<td align=right ><span class=negative >↑</span> 1,480.69B<td align=right ><span class=negative >↑</span> 11.10B<td align=right ><span class=positive >↓</span> 0.75&#37;<td align=right ><span class=negative >↑</span> 26.95B<td align=right ><span class=negative >↑</span> 22.88&#37;<tr><td align=right >SIMD MatMul<td align=right >46.39<td align=right ><span class=positive >↓</span> 5.78×<td align=right ><span class=positive >↑</span> 2.58<td align=right ><span class=negative >↑</span> 1,877.24B<td align=right ><span class=positive >↓</span> 5.22B<td align=right ><span class=positive >↓</span> 2.78&#37;<td align=right ><span class=positive >↓</span> 10.26B<td align=right ><span class=positive >↓</span> 1.64&#37;</table> <h3 id=key_observations ><a href="#key_observations" class=header-anchor >Key Observations</a></h3> <ol> <li><p><strong>SIMD is King</strong>: The SIMD implementation achieves a remarkable 5.78× speedup &#40;46.39s&#41;, crushing all scalar implementations. This is the power of data-level parallelism through AVX/FMA instructions.</p> <li><p><strong>Loop Reordering is Transformational</strong>: Simple loop reordering achieves a 1.80× speedup and dramatically improves IPC from 1.70 to 5.20, while reducing L1 D-cache miss rate from 14.79&#37; to 0.64&#37;. This is the most impactful scalar optimization.</p> <li><p><strong>Half Tiling Edges Ahead</strong>: Among scalar implementations, the half-tiled approach provides the best performance at 146.10s &#40;1.84× speedup&#41; with an IPC of 5.27, though the improvement over loop reordering is only 2&#37;.</p> <li><p><strong>Inner Tiling Shows Minimal Benefit</strong>: Both inner tile sizes &#40;512 and 64&#41; perform virtually identically to simple loop reordering, maintaining excellent IPC &#40;~5.18-5.19&#41; and low cache miss rates &#40;~2.3-2.6&#37;&#41;. The added complexity provides no measurable benefit.</p> <li><p><strong>Full Tiling Catastrophically Regresses</strong>: Both fully tiled implementations &#40;512 and 64 tile sizes&#41; perform <strong>worse than the baseline</strong>, taking 281s and 271s respectively. Despite having the lowest L1 D-cache miss rates &#40;0.41&#37; and 0.75&#37;&#41;, they suffer from:</p> <ul> <li><p>2.6× more instructions executed &#40;4,892B vs 1,860B&#41;</p> <li><p>3× more L1 D-cache loads &#40;1,509B vs 486B&#41;</p> <li><p>Massively increased cache references &#40;21-27B vs 11B&#41;</p> <li><p>Severe cache pollution &#40;26.13&#37; and 22.88&#37; cache miss rates&#41;</p> </ul> <li><p><strong>SIMD&#39;s Interesting Tradeoff</strong>: While SIMD is fastest overall, it has:</p> <ul> <li><p>Lower IPC &#40;2.58&#41; than cache-optimized scalar code &#40;5.20&#41;</p> <li><p>Higher L1 D-cache miss rate &#40;2.78&#37;&#41; than optimized scalar &#40;0.64&#37;&#41;</p> <li><p>But compensates through vectorization: processing 8 floats per instruction</p> <li><p>Still achieves excellent cache reference efficiency &#40;1.64&#37; miss rate vs 45.85&#37; baseline&#41;</p> </ul> </ol> <h3 id=detailed_metrics ><a href="#detailed_metrics" class=header-anchor >Detailed Metrics</a></h3> <h4 id=instructions_and_cycles ><a href="#instructions_and_cycles" class=header-anchor >Instructions and Cycles</a></h4> <table><tr><th align=right >Approach<th align=right >Instructions<th align=right >CPU Cycles<th align=right >IPC<th align=right >Branch Miss Rate<tr><td align=right >Simple MatMul<td align=right >1,860.63B<td align=right >1,092.93B<td align=right >1.70<td align=right >0.11&#37;<tr><td align=right >Loop Reordered<td align=right >3,096.26B<td align=right >595.10B<td align=right ><span class=positive >↑</span> 5.20<td align=right ><span class=positive >↓</span> 0.07&#37;<tr><td align=right >Inner Tiled &#40;512&#41;<td align=right >3,097.33B<td align=right >597.09B<td align=right ><span class=positive >↑</span> 5.19<td align=right ><span class=positive >↓</span> 0.07&#37;<tr><td align=right >Inner Tiled &#40;64&#41;<td align=right >3,095.96B<td align=right >597.28B<td align=right ><span class=positive >↑</span> 5.18<td align=right ><span class=positive >↓</span> 0.07&#37;</table> <p><strong>Key Insight</strong>: The optimized versions execute ~66&#37; more instructions but complete in ~45&#37; fewer cycles, resulting in 3× higher IPC. This demonstrates that instruction count alone is a poor performance metric—what matters is how efficiently the CPU pipeline can execute those instructions.</p> <h4 id=cache_behavior ><a href="#cache_behavior" class=header-anchor >Cache Behavior</a></h4> <table><tr><th align=right >Approach<th align=right >L1 D-cache Loads<th align=right >L1 D-cache Misses<th align=right >Miss Rate<th align=right >L1 D-cache Prefetches<tr><td align=right >Simple MatMul<td align=right >486.39B<td align=right >71.92B<td align=right >14.79&#37;<td align=right >27.07B<tr><td align=right >Loop Reordered<td align=right >895.81B<td align=right ><span class=positive >↓</span> 5.69B<td align=right ><span class=positive >↓</span> 0.64&#37;<td align=right ><span class=positive >↓</span> 4.91B<tr><td align=right >Inner Tiled &#40;512&#41;<td align=right >896.33B<td align=right ><span class=positive >↓</span> 5.78B<td align=right ><span class=positive >↓</span> 0.65&#37;<td align=right ><span class=positive >↓</span> 4.92B<tr><td align=right >Inner Tiled &#40;64&#41;<td align=right >895.92B<td align=right ><span class=positive >↓</span> 5.79B<td align=right ><span class=positive >↓</span> 0.65&#37;<td align=right ><span class=positive >↓</span> 4.95B</table> <p><strong>Key Insight</strong>: Despite nearly doubling the number of L1 D-cache loads &#40;from 486B to 896B&#41;, the optimized versions reduce cache misses by 92&#37; &#40;from 71.92B to ~5.7B&#41;. This dramatic improvement in miss rate demonstrates the power of spatial locality.</p> <h3 id=analysis ><a href="#analysis" class=header-anchor >Analysis</a></h3> <p>The profiling data reveals several important insights:</p> <ol> <li><p><strong>Data-Level Parallelism Dominates</strong>: SIMD vectorization &#40;5.78× speedup&#41; provides 3× better performance than the best cache optimization &#40;1.84× speedup&#41;. When applicable, vectorization is the single most impactful optimization technique.</p> <li><p><strong>Memory Access Patterns Matter Most &#40;for Scalar Code&#41;</strong>: Among scalar implementations, simple loop reordering has the most dramatic impact, reducing L1 D-cache misses by 92&#37; &#40;from 71.92B to 5.69B&#41; by improving spatial locality. This single change delivers 1.80× speedup.</p> <li><p><strong>IPC as a Key Metric for Scalar Code</strong>: The cache-optimized scalar versions achieve 3× higher IPC &#40;from 1.70 to ~5.20&#41;, indicating much better CPU pipeline utilization with fewer stalls waiting for memory. This high IPC shows the CPU pipeline running at near-peak efficiency.</p> <li><p><strong>SIMD&#39;s Different Performance Profile</strong>: SIMD has lower IPC &#40;2.58&#41; than scalar optimized code &#40;5.20&#41;, but wins through throughput—each instruction processes 8 floats instead of 1. This demonstrates that <strong>IPC alone is not a complete performance metric</strong> when comparing scalar vs vector code.</p> <li><p><strong>Diminishing Returns from Complex Tiling</strong>: Additional inner tiling optimizations provide virtually no benefit over simple loop reordering for this 4096×4096 matrix size. Performance varies by less than 0.5&#37; between loop reordering, half tiling, and inner tiling.</p> <li><p><strong>The Fully Tiled Catastrophe</strong>: Full tiling performs worse than even the baseline&#33; Despite achieving the best L1 D-cache miss rates, it suffers from:</p> <ul> <li><p><strong>Loop overhead</strong>: 2.6× more instructions due to nested loop complexity</p> <li><p><strong>Cache pollution</strong>: Irregular access patterns cause 26&#37; cache miss rates at higher levels</p> <li><p><strong>TLB pressure</strong>: More complex addressing increases virtual-to-physical translation overhead</p> </ul> <p>This proves that <strong>optimizing for one metric &#40;L1 miss rate&#41; can harm overall performance</strong>.</p> <li><p><strong>The Paradox of More Instructions</strong>: Cache-optimized scalar code executes 66&#37; more instructions &#40;3,096B vs 1,860B&#41; but runs 45&#37; faster. The fully tiled code executes 2.6× more instructions and runs slower. This shows instruction count correlates with performance only when memory behavior is similar.</p> <li><p><strong>Hardware Prefetching Adapts to Code Quality</strong>: </p> <ul> <li><p>Poor locality code &#40;simple matmul&#41;: 27B prefetches → trying to compensate</p> <li><p>Good locality code &#40;optimized&#41;: ~5B prefetches → works efficiently</p> <li><p>This suggests modern prefetchers work best with already-good code, rather than fixing bad code.</p> </ul> <li><p><strong>Branch Prediction Impact</strong>: Branch miss rate decreases from 0.11&#37; to 0.07&#37; in optimized versions. While already excellent, this 36&#37; reduction contributes to the performance gain. Modern CPUs have remarkably good branch predictors.</p> </ol> <h3 id=what_we_learned ><a href="#what_we_learned" class=header-anchor >What We Learned</a></h3> <p>Using <code>perf</code> to collect hardware performance counters provides invaluable insights that wall-clock time alone cannot reveal:</p> <ul> <li><p><strong>Vectorization &#40;SIMD&#41;</strong> is the most powerful optimization when applicable</p> <li><p><strong>Memory locality</strong> is the most important factor for scalar code performance</p> <li><p><strong>IPC</strong> is meaningful only when comparing similar code &#40;scalar vs scalar, SIMD vs SIMD&#41;</p> <li><p><strong>Cache miss rate</strong> matters, but only at the right level—L1 optimization can hurt LLC/DRAM performance</p> <li><p><strong>Instruction count</strong> is almost meaningless without memory and execution context</p> <li><p><strong>Simple, predictable access patterns</strong> enable both cache efficiency and hardware prefetching</p> <li><p><strong>Over-optimization can hurt</strong>: Complexity has real costs in instructions and cache behavior</p> </ul> <p>The key lesson: <strong>Focus on the right optimization for your bottleneck</strong>. For this workload:</p> <ol> <li><p>First: Add SIMD &#40;5.78× speedup&#41;</p> <li><p>Second: Fix memory access patterns &#40;1.80× speedup&#41; </p> <li><p>Third: Stop—additional complexity provides no benefit</p> </ol> </div> </div> </div> <div class=page__footer > <footer> <section class=social-icons > <div class=social-icons-container > <a href="https://x.com/Sov_trotter" target=_blank  class=social-icon  data-handle="@yourusername" title="X (formerly Twitter)"> <svg width=24  height=24  viewBox="0 0 24 24" fill=currentColor > <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/> </svg> <span class=social-handle >@Sov_trotter</span> </a> <a href="https://linkedin.com/in/Sov-trotter" target=_blank  class=social-icon  data-handle=yourusername  title=LinkedIn > <svg width=24  height=24  viewBox="0 0 24 24" fill=currentColor > <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/> </svg> <span class=social-handle >Sov-trotter</span> </a> <a href="https://github.com/Sov-trotter" target=_blank  class=social-icon  title=GitHub > <svg width=24  height=24  viewBox="0 0 24 24" fill=currentColor > <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/> </svg> </a> <a href="mailto:sharmarsh15@gmail.com" class=social-icon  title=Email > <svg width=24  height=24  viewBox="0 0 24 24" fill=currentColor > <path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/> </svg> </a> </div> </section> <div class=page__footer-copyright >&copy; Arsh Sharma. Powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin</a> &amp; <a href="https://julialang.org" rel=nofollow >The Julia Language</a>.</div> </footer> </div> <script src="/libs/minimal-mistakes/main.min.js"></script> <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin=anonymous ></script> <script src="https://unpkg.com/typed.js@2.0.16/dist/typed.umd.js" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/npm/typed.js@2.0.16/dist/typed.umd.js';"></script> <script> document.addEventListener('DOMContentLoaded', function() { var typewriterElement = document.querySelector('.typewriter'); if (typewriterElement && typeof Typed !== 'undefined') { new Typed('.typewriter', { strings: ['नमस्ते।', 'Namaste', 'ನಮಸ್ಕಾರ', 'வணக்கம்', 'നമസ്കാരം', 'নমস্কার', 'नमस्कारः', 'नमस्कार', 'નમસ્કાર', 'Hola', 'Bonjour'], typeSpeed: 120, backSpeed: 50, loop: true, showCursor: true, cursorChar: '|', autoInsertCss: true, backDelay: 2000, startDelay: 1000 }); } else if (typewriterElement) { typewriterElement.textContent = 'नमस्ते।'; } }); </script> <script> document.addEventListener('DOMContentLoaded', function() { const hamburgerButton = document.querySelector('.greedy-nav__toggle'); const hiddenLinks = document.querySelector('.hidden-links'); const visibleLinks = document.querySelector('.visible-links'); if (hamburgerButton && hiddenLinks) { document.addEventListener('click', function(event) { const isClickInsideNav = hamburgerButton.contains(event.target) || hiddenLinks.contains(event.target) || visibleLinks.contains(event.target); if (!isClickInsideNav && !hiddenLinks.classList.contains('hidden')) { hamburgerButton.click(); } }); document.addEventListener('keydown', function(event) { if (event.key === 'Escape' && !hiddenLinks.classList.contains('hidden')) { hamburgerButton.click(); } }); } }); </script> <script> document.addEventListener('DOMContentLoaded', function() { document.querySelectorAll('.franklin-toc').forEach(function(toc) { const tocList = toc.querySelector('ol'); if (!tocList) return; const header = document.createElement('div'); header.className = 'toc-header'; header.textContent = '▼ Table of Contents'; header.style.cssText = 'cursor:pointer;user-select:none;'; toc.insertBefore(header, tocList); tocList.style.overflow = 'hidden'; tocList.style.transition = 'max-height 0.3s ease-in-out'; let isCollapsed = false; requestAnimationFrame(() => { tocList.style.maxHeight = tocList.scrollHeight + 'px'; }); header.addEventListener('click', function() { isCollapsed = !isCollapsed; if (isCollapsed) { tocList.style.maxHeight = '0'; header.textContent = '▶ Table of Contents'; } else { tocList.style.maxHeight = tocList.scrollHeight + 'px'; header.textContent = '▼ Table of Contents'; } }); }); }); </script> <button id=scroll-to-top  class=scroll-to-top  aria-label="Scroll to top"> <svg width=24  height=24  viewBox="0 0 24 24" fill=currentColor > <path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"/> </svg> </button> <script> document.addEventListener('DOMContentLoaded', function() { const scrollBtn = document.getElementById('scroll-to-top'); if (!scrollBtn) return; scrollBtn.classList.remove('visible'); function toggleScrollButton() { if (window.pageYOffset > 300) { scrollBtn.classList.add('visible'); } else { scrollBtn.classList.remove('visible'); } } toggleScrollButton(); window.addEventListener('scroll', toggleScrollButton); scrollBtn.addEventListener('click', function(e) { e.preventDefault(); window.scrollTo({ top: 0, behavior: 'smooth' }); }); }); </script>